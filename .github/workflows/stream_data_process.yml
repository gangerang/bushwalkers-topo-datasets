name: Streams height data processing workflow

on:
  # schedule:
    # - cron: '0 * * * *'  # Runs every hour at the top of the hour
  workflow_dispatch:  # Allows for manual triggering

jobs:
  data_processing_job:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout main branch (for scripts)
        uses: actions/checkout@v4
        with:
          ref: main
          path: main

      - name: Checkout data branch
        uses: actions/checkout@v4
        with:
          ref: data
          path: data
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas geopandas requests shapely

      - name: Run BOM Processing Script
        env:
          FTP_HOST: "ftp.bom.gov.au"
          FTP_DIRECTORY: "/anon/gen/fwo/"
          OUTPUT_DIR: data/dynamic/bom
          INPUT_DIR: data/static/bom
        run: python main/scripts/bom_stream_data_process.py

      - name: Configure Git
        working-directory: data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Commit and Push Changes
        working-directory: data
        run: |
          git add -A
          git diff --staged --quiet || git commit -m "Update BOM stream gauge data"
          git pull --rebase origin data
          git push origin data
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
